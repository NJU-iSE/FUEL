method: "remote"
config:
  model: "deepseek-chat" # @SHAOYU: model name is provided by your API server
  url: "https://api.deepseek.com/beta"  # @SHAOYU: similar with above
  key_file: "config/deepseek-key.txt"
  retry_times: 5  # retry times used to handle the unstable API service
  timeout: 60  # timeout setting (seconds)
  frequency_penalty: 2  # range from [-2,2]. if set > 0, decreasing the model's likelihood to repeat the same line verbatim.
  max_tokens: 4096  # the max length of the output (Beta maximum 8192)
  presence_penalty: 2  # range from [-2,2]. if set > 0, increasing the model's likelihood to talk about new topics.
  response_format: # another type is json
    type: "text"
  stop: ["```"]  # can be set to `String` or `List`. When meeting these words. API would stop to analyze more tokens.
  stream: false
  stream_options: null
  temperature: 2  # [deepseek official API config]: range from [0, 2]. Higher values like 0.8 will make the output more random
  top_p: 1  # An alternative to sampling with temperature, called nucleus sampling. We generally recommend altering this or `temperature` but not both
  tools: null  # A list of tools the model may call.
  tool_choice: "none"
  logprobs: false
  top_logprobs: null